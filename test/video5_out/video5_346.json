{"opt": {"output_dir": "", "num_to_draw": 10, "final_nms_thresh": 0.3, "use_cudnn": 1, "text_size": 2, "max_images": 100, "gpu": -1, "splits_json": "info/densecap_splits.json", "vg_img_root_dir": "", "checkpoint": "data/models/densecap/densecap-pretrained-vgg16.t7", "num_proposals": 1000, "rpn_nms_thresh": 0.7, "image_size": 720, "input_image": "/home/akash/learn/598/project/video-context-transcription/test/video5/video5_346.jpg", "input_split": "", "box_width": 2, "input_dir": "", "output_vis_dir": "/home/akash/learn/598/project/video-context-transcription/src/python/default_out_dir", "output_vis": 1}, "results": [{"img_name": "video5_346.jpg", "scores": [5.0974984169006, 2.1863300800323, 1.9948647022247, 1.914253950119, 1.6914746761322, 1.3309580087662, 0.94591927528381, 0.87948954105377], "captions": ["a man and woman on a computer", "a box of food", "the woman is smiling", "the man has short hair", "yellow sign with black lettering", "man standing in front of a store", "a white laptop on the table", "brown wooden table"], "boxes": [[-10.593353271484, 56.324295043945, 689.09338378906, 349.62591552734], [458.36141967773, 94.729904174805, 267.48123168945, 287.88665771484], [151.70387268066, 11.764495849609, 244.72801208496, 343.06216430664], [205.28971862793, 10.564819335938, 161.62239074707, 155.59526062012], [2.0848598480225, 214.19314575195, 47.025238037109, 71.343383789062], [54.935882568359, 130.82275390625, 146.92593383789, 183.84149169922], [325.25280761719, 86.205184936523, 241.03942871094, 268.95178222656], [55.196182250977, 333.67547607422, 222.37889099121, 68.269897460938]], "sg": [{"relationships": [{"predicate": "on", "subject": 0, "text": ["man", "on", "computer"], "object": 1}], "phrase": "", "objects": [{"names": ["man"]}, {"names": ["computer"]}], "attributes": [], "id": 0, "url": "0"}, {"relationships": [{"predicate": "of", "subject": 0, "text": ["box", "of", "food"], "object": 1}], "phrase": "", "objects": [{"names": ["box"]}, {"names": ["food"]}], "attributes": [], "id": 0, "url": "0"}, {"relationships": [], "phrase": "", "objects": [{"names": ["woman"]}], "attributes": [{"predicate": "is", "subject": 0, "attribute": "smile", "text": ["woman", "is", "smile"], "object": "smile"}], "id": 0, "url": "0"}, {"relationships": [{"predicate": "have", "subject": 0, "text": ["man", "have", "hair"], "object": 1}], "phrase": "", "objects": [{"names": ["man"]}, {"names": ["hair"]}], "attributes": [{"predicate": "is", "subject": 1, "attribute": "short", "text": ["hair", "is", "short"], "object": "short"}], "id": 0, "url": "0"}, {"relationships": [{"predicate": "with", "subject": 0, "text": ["sign", "with", "lettering"], "object": 1}], "phrase": "", "objects": [{"names": ["sign"]}, {"names": ["lettering"]}], "attributes": [{"predicate": "is", "subject": 0, "attribute": "yellow", "text": ["sign", "is", "yellow"], "object": "yellow"}, {"predicate": "is", "subject": 1, "attribute": "black", "text": ["lettering", "is", "black"], "object": "black"}], "id": 0, "url": "0"}, {"relationships": [{"predicate": "in", "subject": 0, "text": ["man standing", "in", "front"], "object": 1}, {"predicate": "of", "subject": 0, "text": ["man standing", "of", "store"], "object": 2}], "phrase": "", "objects": [{"names": ["man standing"]}, {"names": ["front"]}, {"names": ["store"]}], "attributes": [], "id": 0, "url": "0"}, {"relationships": [{"predicate": "on", "subject": 0, "text": ["laptop", "on", "table"], "object": 1}], "phrase": "", "objects": [{"names": ["laptop"]}, {"names": ["table"]}], "attributes": [{"predicate": "is", "subject": 0, "attribute": "white", "text": ["laptop", "is", "white"], "object": "white"}], "id": 0, "url": "0"}, {"relationships": [], "phrase": "", "objects": [{"names": ["table"]}], "attributes": [{"predicate": "is", "subject": 0, "attribute": "wooden", "text": ["table", "is", "wooden"], "object": "wooden"}, {"predicate": "is", "subject": 0, "attribute": "brown", "text": ["table", "is", "brown"], "object": "brown"}], "id": 0, "url": "0"}]}]}