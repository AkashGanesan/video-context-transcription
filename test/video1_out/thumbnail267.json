{"opt": {"output_dir": "", "num_to_draw": 10, "final_nms_thresh": 0.3, "use_cudnn": 1, "text_size": 2, "max_images": 100, "gpu": -1, "splits_json": "info/densecap_splits.json", "vg_img_root_dir": "", "checkpoint": "data/models/densecap/densecap-pretrained-vgg16.t7", "num_proposals": 1000, "rpn_nms_thresh": 0.7, "image_size": 720, "input_image": "/home/akash/learn/598/project/video-context-transcription/test/video1/thumbnail267.jpg", "input_split": "", "box_width": 2, "input_dir": "", "output_vis_dir": "/home/akash/learn/598/project/video-context-transcription/src/python/default_out_dir", "output_vis": 1}, "results": [{"img_name": "thumbnail267.jpg", "scores": [1.4473991394043, 1.2500773668289], "captions": ["black and white photo", "a brown and white bag"], "boxes": [[0.56744384765625, 53.975936889648, 557.52587890625, 351.58563232422], [204.2864074707, 161.8434753418, 166.02655029297, 177.93417358398]], "sg": [{"relationships": [], "phrase": "", "objects": [{"names": ["photo"]}], "attributes": [{"predicate": "is", "subject": 0, "attribute": "white", "text": ["photo", "is", "white"], "object": "white"}], "id": 0, "url": "0"}, {"relationships": [], "phrase": "", "objects": [{"names": ["bag"]}], "attributes": [{"predicate": "is", "subject": 0, "attribute": "white", "text": ["bag", "is", "white"], "object": "white"}, {"predicate": "is", "subject": 0, "attribute": "brown", "text": ["bag", "is", "brown"], "object": "brown"}], "id": 0, "url": "0"}]}]}